#!/usr/bin/env python
# -*- coding: utf-8 -*-

#Autor:
#Annelyse Schatzmann         GRR20151731


import readC10 as r
import numpy as np  
from matplotlib import pyplot as plt
# from keras.datasets import cifar10
# from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator



# defining the settings
# batch_size = 32
# nb_classes = 10
# nb_epoch = 10
# img_channels = 3
# img_rows, img_cols = 32, 32

def data_augmentation(model, X_train, Y_train, X_test, Y_test): 
    # This will do preprocessing and realtime data augmentation:
   
    sgd = SGD(lr = 0.01, decay=1e-6, momentum=0.9, nesterov=True)
    datagen = model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

    datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images

    # Compute quantities required for featurewise normalization
    cnn = datagen.fit(X_train)

    # Fit the model on the batches generated by datagen.flow().
    cnn = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = 64),
                                 samples_per_epoch = X_train.shape[0] // 64, epochs = 10, 
                                 validation_data =(X_test, Y_test), verbose=2)

   
    
    scores = model.evaluate(X_test, Y_test, batch_size=64)
    print('Test loss : ', scores[0])
    print('Test accuracy : ', scores[1])

    return cnn



def cria_modelo():
	
	model = Sequential()
	model.add(Convolution2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3)))
	model.add(Activation('relu'))
	model.add(Convolution2D(64, kernel_size=(3, 3), dim_ordering="th"))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Dropout(0.25))

	model.add(Flatten())
   	model.add(Dense(50))
   	model.add(Activation('relu'))
   
   	model.add(Dense(10))
   	model.add(Activation('softmax'))

	
	return model


def treinamento(model, X_train, Y_train, X_test, Y_test):
	
	sgd = SGD(lr = 0.01, decay=1e-6, momentum=0.9, nesterov=True)
 	cnn = model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

   # model.fit(X_train, Y_train, nb_epoch=100, batch_size=32, validation_split=0.1, show_accuracy=True, verbose=1)
	cnn = model.fit(X_train, Y_train, batch_size=64, epochs=10, validation_data=(X_test, Y_test), shuffle=True)

	print('Testing...')
	scores = model.evaluate(X_test, Y_test, batch_size=64, verbose=1)
	print("--------")
	print('Test loss : ', scores[0])
	print('Accuracy: {0}'.format(scores[1]))

	return cnn


	

if __name__ == '__main__':
	X_train, Y_train, X_test, Y_test = r.get_CIFAR10_data()


	print('\n')
	num = input('Digite 1 para CNN com dados reais ou 2 para o data augmentation')
	print('\n')

	model = cria_modelo()
	if(num == 1):
		# model.summary()
		cnn = treinamento(model, X_train, Y_train, X_test, Y_test)
		nome = 'CNN'
	else:
		cnn = data_augmentation(model, X_train, Y_train, X_test, Y_test)
		nome = 'Data augmentation'
		

	plt.figure(0)
	plt.plot(cnn.history['acc'],'r')
	plt.plot(cnn.history['val_acc'],'g')
	plt.xticks(np.arange(0, 11, 2.0))
	plt.rcParams['figure.figsize'] = (8, 6)
	plt.xlabel("Num of Epochs")
	plt.ylabel("Accuracy")
	plt.title("Training Accuracy vs Validation Accuracy")
	plt.legend(['train','validation'])
	

	plt.figure(1)
	plt.plot(cnn.history['loss'],'r')
	plt.plot(cnn.history['val_loss'],'g')
	plt.xticks(np.arange(0, 11, 2.0))
	plt.rcParams['figure.figsize'] = (8, 6)
	plt.xlabel("Num of Epochs")
	plt.ylabel("Loss")
	plt.title("Training Loss vs Validation Loss")
	plt.legend(['train','validation'])
	 
	 
	plt.show()